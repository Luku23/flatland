{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Flatland project\n",
        "\n"
      ],
      "metadata": {
        "id": "f_sEckl_O0Dr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Import and procces the data"
      ],
      "metadata": {
        "id": "4URF0fDzPjfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import necessary libraries"
      ],
      "metadata": {
        "id": "VeMias5OQGpB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "L_yesALc6Uxl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pickle, gzip\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load train and test data from files"
      ],
      "metadata": {
        "id": "Quuxu82BRlja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data function\n",
        "def load_data(path_to_data):\n",
        "    with gzip.open(path_to_data, 'rb') as file:\n",
        "        X, y = pickle.load(file)\n",
        "    return X, y\n",
        "\n",
        "# Paths to data files\n",
        "path_to_train_data = 'flatland_train.data'\n",
        "path_to_test_data = 'flatland_test.data'\n",
        "\n",
        "# Load the data\n",
        "X, y = load_data(path_to_train_data)\n",
        "X_TESTT, y_TESTT = load_data(path_to_test_data)"
      ],
      "metadata": {
        "id": "K7dSb3Pj6h7v"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Do a train-test split on the train data so we can check if the trained model is somewhat accurate"
      ],
      "metadata": {
        "id": "cwMM3NlIR5uJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "hXEY8Z5TGZR-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert all of the data to tensors because we are working with pytorch, and you can send tensors to GPU."
      ],
      "metadata": {
        "id": "bWb5SHFiT2fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train data from the split\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "# Test data from the split\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Main test data that we use in the end to get 10k character string\n",
        "X_TESTT_tensor = torch.tensor(X_TESTT, dtype=torch.float32).unsqueeze(1)"
      ],
      "metadata": {
        "id": "z9iaRxOU7vdN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create data set and data loader for the split data."
      ],
      "metadata": {
        "id": "qv_OpkRBXXzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor) # Pairs the training data X_train_tensor with its corresponding labels y_train_tensor\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor) # Pairs the testing data X_test_tensor with its corresponding labels y_test_tensor\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) # Creates a loader for the train_dataset for efficient work\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False) # Creates a loader for the test_dataset for efficient work"
      ],
      "metadata": {
        "id": "GyomF-Kw8SNW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image plot function"
      ],
      "metadata": {
        "id": "bunuFPdwYxV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(image, label=None):\n",
        "    # Convert to NumPy if the image is a tensor\n",
        "    if isinstance(image, torch.Tensor):\n",
        "        image = image.squeeze().cpu().numpy()  # Remove channel dimension and move to CPU if necessary\n",
        "\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    if label is not None:\n",
        "        plt.title(f\"Label: {label}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "nx7WG55y-1U0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the image plot function"
      ],
      "metadata": {
        "id": "vntDLVjqY04P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_loader.dataset[0]\n",
        "plot(image, label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "10clZvYNANFA",
        "outputId": "6278b6d3-7e90-4b9c-8361-ea28cbaedcf4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check if CUDA (GPU) is available, otherwise check for MPS, else use CPU"
      ],
      "metadata": {
        "id": "e4CPCJZPZDAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do_bm_0fBdtr",
        "outputId": "e28b2f95-d3b1-4483-9f94-3b8c1cc5e15e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural network\n",
        "### Convolutional neural network architecture\n",
        "\n",
        "In this architecture we use 3 convolutional layers, batch normalization after each one, max pooling, 2 fully connected layers with 50% dropout"
      ],
      "metadata": {
        "id": "yogEOeiCZfKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        # 1st conv. layer - input 1 image, output 32 features\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32) # stabilize and speed up training by normalizing weights\n",
        "\n",
        "        # 2nd conv. layer - input 32 features, output 64 features\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64) # stabilize and speed up training by normalizing weights\n",
        "\n",
        "        # 3rd conv. layer - input 64 features, output 128 features\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128) # stabilize and speed up training by normalizing weights\n",
        "\n",
        "\n",
        "        # Pooling layer\n",
        "        # Used to reduce weight and height by half\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 6 * 6, 64) # 128 channels and 6x6 feature maps after pooling\n",
        "        self.fc2 = nn.Linear(64, 8)\n",
        "\n",
        "        # Dropout layer\n",
        "        # Used to prevent overfitting\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers with batch normalization, relu, and maxpooling\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "        # Flatten the tensor so it can be passed through fully connected layers\n",
        "        x = x.view(x.size(0), -1)\n",
        "        #x = torch.flatten(x, 1)\n",
        "\n",
        "        # Fully connected layers with dropout\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = CNN().to(device) # Create model, send to device\n",
        "criterion = nn.CrossEntropyLoss() # Cross Entropy Loss for criterion\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Adam with learning rate of 0.001 optimizer"
      ],
      "metadata": {
        "id": "Bp6VBoeVyHVZ"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "Bn5264RJe8dE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs to train\n",
        "num_epochs = 150\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        # Move data to the device (GPU or CPU)\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update parameters\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset) # Calculate average loss for the epoch\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrYhmea8MpVR",
        "outputId": "7d83a4f8-e312-48cd-9dbb-b2ceddc2c470"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/150], Loss: 0.03216\n",
            "Epoch [2/150], Loss: 0.03098\n",
            "Epoch [3/150], Loss: 0.03925\n",
            "Epoch [4/150], Loss: 0.03076\n",
            "Epoch [5/150], Loss: 0.02863\n",
            "Epoch [6/150], Loss: 0.03931\n",
            "Epoch [7/150], Loss: 0.03910\n",
            "Epoch [8/150], Loss: 0.03604\n",
            "Epoch [9/150], Loss: 0.03953\n",
            "Epoch [10/150], Loss: 0.03711\n",
            "Epoch [11/150], Loss: 0.03867\n",
            "Epoch [12/150], Loss: 0.04069\n",
            "Epoch [13/150], Loss: 0.03142\n",
            "Epoch [14/150], Loss: 0.03635\n",
            "Epoch [15/150], Loss: 0.02895\n",
            "Epoch [16/150], Loss: 0.03593\n",
            "Epoch [17/150], Loss: 0.03064\n",
            "Epoch [18/150], Loss: 0.03034\n",
            "Epoch [19/150], Loss: 0.04289\n",
            "Epoch [20/150], Loss: 0.04387\n",
            "Epoch [21/150], Loss: 0.03450\n",
            "Epoch [22/150], Loss: 0.03717\n",
            "Epoch [23/150], Loss: 0.03671\n",
            "Epoch [24/150], Loss: 0.03727\n",
            "Epoch [25/150], Loss: 0.04151\n",
            "Epoch [26/150], Loss: 0.03796\n",
            "Epoch [27/150], Loss: 0.02951\n",
            "Epoch [28/150], Loss: 0.03108\n",
            "Epoch [29/150], Loss: 0.02827\n",
            "Epoch [30/150], Loss: 0.02786\n",
            "Epoch [31/150], Loss: 0.03622\n",
            "Epoch [32/150], Loss: 0.03780\n",
            "Epoch [33/150], Loss: 0.04294\n",
            "Epoch [34/150], Loss: 0.04413\n",
            "Epoch [35/150], Loss: 0.03981\n",
            "Epoch [36/150], Loss: 0.03035\n",
            "Epoch [37/150], Loss: 0.03677\n",
            "Epoch [38/150], Loss: 0.04375\n",
            "Epoch [39/150], Loss: 0.02776\n",
            "Epoch [40/150], Loss: 0.02881\n",
            "Epoch [41/150], Loss: 0.03505\n",
            "Epoch [42/150], Loss: 0.03102\n",
            "Epoch [43/150], Loss: 0.03016\n",
            "Epoch [44/150], Loss: 0.03705\n",
            "Epoch [45/150], Loss: 0.03707\n",
            "Epoch [46/150], Loss: 0.03160\n",
            "Epoch [47/150], Loss: 0.03403\n",
            "Epoch [48/150], Loss: 0.03843\n",
            "Epoch [49/150], Loss: 0.03765\n",
            "Epoch [50/150], Loss: 0.04042\n",
            "Epoch [51/150], Loss: 0.03335\n",
            "Epoch [52/150], Loss: 0.03321\n",
            "Epoch [53/150], Loss: 0.03289\n",
            "Epoch [54/150], Loss: 0.03190\n",
            "Epoch [55/150], Loss: 0.03598\n",
            "Epoch [56/150], Loss: 0.03638\n",
            "Epoch [57/150], Loss: 0.03452\n",
            "Epoch [58/150], Loss: 0.03916\n",
            "Epoch [59/150], Loss: 0.02986\n",
            "Epoch [60/150], Loss: 0.02867\n",
            "Epoch [61/150], Loss: 0.03200\n",
            "Epoch [62/150], Loss: 0.03555\n",
            "Epoch [63/150], Loss: 0.03032\n",
            "Epoch [64/150], Loss: 0.03186\n",
            "Epoch [65/150], Loss: 0.03481\n",
            "Epoch [66/150], Loss: 0.03647\n",
            "Epoch [67/150], Loss: 0.03389\n",
            "Epoch [68/150], Loss: 0.03395\n",
            "Epoch [69/150], Loss: 0.04441\n",
            "Epoch [70/150], Loss: 0.04506\n",
            "Epoch [71/150], Loss: 0.02857\n",
            "Epoch [72/150], Loss: 0.02775\n",
            "Epoch [73/150], Loss: 0.03381\n",
            "Epoch [74/150], Loss: 0.03420\n",
            "Epoch [75/150], Loss: 0.03342\n",
            "Epoch [76/150], Loss: 0.02873\n",
            "Epoch [77/150], Loss: 0.02477\n",
            "Epoch [78/150], Loss: 0.03384\n",
            "Epoch [79/150], Loss: 0.02950\n",
            "Epoch [80/150], Loss: 0.03793\n",
            "Epoch [81/150], Loss: 0.03233\n",
            "Epoch [82/150], Loss: 0.03104\n",
            "Epoch [83/150], Loss: 0.03395\n",
            "Epoch [84/150], Loss: 0.03108\n",
            "Epoch [85/150], Loss: 0.03779\n",
            "Epoch [86/150], Loss: 0.02760\n",
            "Epoch [87/150], Loss: 0.04813\n",
            "Epoch [88/150], Loss: 0.04318\n",
            "Epoch [89/150], Loss: 0.04933\n",
            "Epoch [90/150], Loss: 0.03548\n",
            "Epoch [91/150], Loss: 0.02594\n",
            "Epoch [92/150], Loss: 0.02591\n",
            "Epoch [93/150], Loss: 0.02628\n",
            "Epoch [94/150], Loss: 0.02419\n",
            "Epoch [95/150], Loss: 0.02353\n",
            "Epoch [96/150], Loss: 0.02375\n",
            "Epoch [97/150], Loss: 0.02114\n",
            "Epoch [98/150], Loss: 0.02238\n",
            "Epoch [99/150], Loss: 0.02127\n",
            "Epoch [100/150], Loss: 0.02523\n",
            "Epoch [101/150], Loss: 0.02267\n",
            "Epoch [102/150], Loss: 0.01743\n",
            "Epoch [103/150], Loss: 0.01685\n",
            "Epoch [104/150], Loss: 0.01899\n",
            "Epoch [105/150], Loss: 0.03556\n",
            "Epoch [106/150], Loss: 0.02463\n",
            "Epoch [107/150], Loss: 0.02740\n",
            "Epoch [108/150], Loss: 0.01887\n",
            "Epoch [109/150], Loss: 0.02364\n",
            "Epoch [110/150], Loss: 0.02286\n",
            "Epoch [111/150], Loss: 0.02287\n",
            "Epoch [112/150], Loss: 0.01975\n",
            "Epoch [113/150], Loss: 0.02665\n",
            "Epoch [114/150], Loss: 0.02283\n",
            "Epoch [115/150], Loss: 0.02537\n",
            "Epoch [116/150], Loss: 0.03000\n",
            "Epoch [117/150], Loss: 0.01998\n",
            "Epoch [118/150], Loss: 0.02052\n",
            "Epoch [119/150], Loss: 0.01952\n",
            "Epoch [120/150], Loss: 0.02330\n",
            "Epoch [121/150], Loss: 0.01844\n",
            "Epoch [122/150], Loss: 0.02798\n",
            "Epoch [123/150], Loss: 0.02105\n",
            "Epoch [124/150], Loss: 0.03565\n",
            "Epoch [125/150], Loss: 0.02278\n",
            "Epoch [126/150], Loss: 0.02048\n",
            "Epoch [127/150], Loss: 0.01719\n",
            "Epoch [128/150], Loss: 0.02264\n",
            "Epoch [129/150], Loss: 0.01736\n",
            "Epoch [130/150], Loss: 0.01655\n",
            "Epoch [131/150], Loss: 0.01892\n",
            "Epoch [132/150], Loss: 0.01898\n",
            "Epoch [133/150], Loss: 0.02146\n",
            "Epoch [134/150], Loss: 0.01987\n",
            "Epoch [135/150], Loss: 0.01860\n",
            "Epoch [136/150], Loss: 0.01730\n",
            "Epoch [137/150], Loss: 0.02245\n",
            "Epoch [138/150], Loss: 0.01819\n",
            "Epoch [139/150], Loss: 0.02021\n",
            "Epoch [140/150], Loss: 0.02124\n",
            "Epoch [141/150], Loss: 0.01447\n",
            "Epoch [142/150], Loss: 0.04252\n",
            "Epoch [143/150], Loss: 0.04155\n",
            "Epoch [144/150], Loss: 0.02359\n",
            "Epoch [145/150], Loss: 0.02671\n",
            "Epoch [146/150], Loss: 0.01610\n",
            "Epoch [147/150], Loss: 0.01248\n",
            "Epoch [148/150], Loss: 0.01851\n",
            "Epoch [149/150], Loss: 0.01304\n",
            "Epoch [150/150], Loss: 0.01535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trained model evaluation\n",
        "\n",
        "Do some tests on the test split"
      ],
      "metadata": {
        "id": "63hFUHO6fkkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation for evaluation\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQuYEMfpOXuC",
        "outputId": "d9c2bc3d-dcb7-4fbb-c2fa-5dc580fe106e"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 98.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now use the trained model on main test set to get a prediction of an array of 10k characters, save the string to a file"
      ],
      "metadata": {
        "id": "n2PIR8L0hYGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize an empty string to hold the predictions\n",
        "prediction_string = \"\"\n",
        "\n",
        "with torch.no_grad():  # No need to track gradients\n",
        "    for image in X_TESTT_tensor:\n",
        "        image = image.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output, 1)  # Get the class with the highest probability\n",
        "        prediction_string += str(predicted.item())  # Append prediction to string\n",
        "\n",
        "# Write the prediction string to a new file\n",
        "with open(\"predictions.txt\", \"w\") as f:\n",
        "    f.write(prediction_string)"
      ],
      "metadata": {
        "id": "jczMTRuCPLqp"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check string"
      ],
      "metadata": {
        "id": "YORf5X9-h0-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "RTzaQIfy181f",
        "outputId": "72b10474-9aae-4cc5-f4b9-ae8ee6f83f36"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'6655533343300063340545565645530463050355660333004363364366664053553303655503053350530663500355355563530403365335355030035360650004655530445455543655355046545635635636556303536656365660360305666463536335363336336465353306053566553350350053500063346060346653500453633456446556354503346300354553655053533306434055363453403030605300053655506334560544330054363500343044350645463346060306563305653645035356533336636330660643355564354536063655433663304055534503505345553050664300303453544505030306345006554333300506636544330334035643535353650403330363553435603556363440550543403430450565505303534536654355435035005453066564566036403330463456364506563043553343345350563053556660564533336350334356345353353060333043533433504556433334035630054450554503643600503355633656300553303033036463454560536453433660605604335456536403330035505464066565430553033305340544530633643635653365030035530440356535354063556033036433354560635036550504640065354330360630635656403363635646435405000566355305355603035300453665356603453560366065300453055344653064505003550633033300355366455363044363455665305346550453346603355040336334366306566035530635645460030055634653536354555666535604535533533503656353455534635504300055363464434540365505330353066633435555505544440035566563454365006365334333654054365343003435466346565433440535554330354534565056636553350566366665345065035504305463055003066363646343506034056346335655363030563036546534303465653566303600330536353336333435335066330534556336543636533063654563643460404363630435655330335563353535300033333343553455054535566334303000403503305355440056456654646036363046453563443454335335365535354333565333546553504546563650503053635566330536553505563435335030303564065630335564353604646660356546334656646035635633405050533555435535053504534305566030353533050033545565535546605453535630533063453436563533555605056505055536054436563044440033550300365503465030335635305543503564033033553435653056553346400556563353436463556034360305553306600055335056563654053560300656335553436354636400330664340333355565343300563355536004040300550065555066565654663363660654645500503003630550436003654440605565505645630336355433505630003304365444333403554503353305534636335445550503645406353033335346063535366004536505054343043033336453305430466350456533534533536333303355666553334455634033053654053353455536650536533336333434535363364433035503535343436364553635550450500435666335606355665650553644340635346054344305443504655533556060034443433535605505656056505054365430550453306065566535536005635355635433355533536333404335360535654440550535363535040636333636434354445040543006605653655360436635564036306435533006345554004534466356330350355030343305300554054355636345535604554430666300406543055354343330335336056053464306503345334566006635336303345550653600660653463633334506505630605464535403660355336456553634040053405653564655635335450353400465565535530003533563335533506646303603630434654530343400453655530533000355666550305343653336630366533660335044300350604430543035603563050306033344665535655030333536346556005546533663660360330535500665336003655054533553303006504450450634555536533463300535503360036660060305034535564335060446450303333433056555555336343330055463646043364344636436545333033030363350533055033603355534653363030645355304633634536330666330045505005663635345535335354505364333555505543543504363556365430445330535345605453000655533404304553403655665353600035505655536635353336506055460044505306453543053003530545433605545643530663530365663560334463546064033535554663345350534036465533560355556653334504545356546435053330000534303546335565465064663063655556056533536530360566530553366653363553453456305045535303640053455366366565536434065605033445353334050564556366535336343633055530045453646560053436633606043356663434330444503453356403503350535330335465553365063505053666400503353035363405356543530544463643305300303650645653330666304353636660043503353334663055500034040500335660550656663334335336336363453534360300356303455663556335043305005353335654660666335543350534445563060645650553536534443463400404005455505436450500000063533330566565665363305653355000563435365655645656333305335063566553500653635654630534444345055353545305656664653306563450036045563034550033543350354553565563503564656055303530566030535405035343554053034363055365055365533355303463566306545363506335534546646653500550646505344500355435643630505536343436300363643530353336606330535535304635555454054635506555366353555345355400430305533655000355360535005653063443654636635650630534606340066305305566354633555355455503600054533433355446356440350530650353503445530334353043044603354035330305450533650405355666553060563433333663636354535463033530543635355530066600034363435554335333065006336554653363663430005364530305003036540353634503300000633634654333533665505665353540005454463634435034463546603650555543540533344640433530543355406440604656645503605530003653553300653533334050333654303600565356460453606546504355350563333636335604355344465540433303500303655550655333503345330533556554350036666053604334340533036436336553535630550563353006003330555604503650663344663353444343653450356536335533503654563304506665535636306445056464503545556556453534336536340405656533060346640545553403630555336443530540603353034635556566334564333330053634303340666403043333433550643535530555563303565553303360336530335065665366063533063460635034533643053065556066036360355365434503560533344643653546504530646336035564633556530303564336033503636500000563555354656663533053043636330453454434545345353556343360363635030063565036330665043560505456545343406653405303335555066033030505533034063506000333053005635035654500656303030065603630653035054363045560455534033546365335333565553554563046305405444533565554604563334034654535660463453063500333600055334336050354466655053533005446555553553633656640334605336503056633563644006663534363303406345503035354304433604636333345630035066355354333003344645665345530055340564543500305553334056333535504344365605545040055334635300655304564403405530555535306345666635536040454455464436343564066633305636650533635053335334450346334300360600534655050034065403404555303436535306655354344655540065355335000650353503650003546535355346350400553433550660035343635030336335563364334536655543540044036303306360654354433033543363443033605035353446336504453306045063060603036553654065540464463055550535443333065555303534354655356500630354360050465535363354350043656055435356635033045360355653505054350435656634336605333333530533363636043000634504656330665033035055345663345634336553363436656453533363543504503343454456655363344340505304503036530553363000633053430503035304005335335340366333430563554655543506554053550346363034035353554054553030335305566364063334360555506643556535343006544030365556560005356333553533003404553354035530466354034553606435543303606565035453353633353366300366536055436456430533333564430565336533353555563665365645400500534055630534306653656560044540456345533534634654536535360355435355633450635435333606553656465353653446356343355535663503560450654446533335604443556033454333406303666665060360350365055033635665300456434534566630536065330463504033443546044300363455355635564350666455550636530355546036350366400655365356304334550553635364353535033650305033063545363046606356355604330543604063466643305533353665333564333354663634354645533345356504305556050506435554454335364333645530336500050535433533630465536335550556636504350045355356466666665035350063335553505330556604336346333443665535660354445543440536406056000653564456536305335555355455343303333335446563453530534653465366650333535053335056336304304000060055630654053345000456634650505066063660543303630503033660036544335364054544603065434033533360406443565306533656534560043333553363556345556665550304650560355606004403606046555653433636355533330303005333456505563556353330533535665005666300366355365004433443530553066530005555665345055436333553355345063635054050634356006506453545446366333333065346665050603665335045366534454050063546305363335643530343343006033555543656553665406655554353335545403605353303536300303556306604363503306560036656530354004365555643440403360303066360433550044534633550603656306354346536435433463564433555000336334504465646643343430405533655534553433430560335463553030644433340335640630346063304433503545533436636563455064443633645633550035304403534045303633604436536403605303550443560300453660350655356450336533003335033366453455545543366560530534430645530356303356655434036365304336305033406003354456003006330665650646033545300463460364403553056534534533300330045656535665555554033505360334500505343464453635565655565503364555554030330005665306334660333036465604500653005360335653563304343035430304635534033303304405454663545065043033430045064550056635453300036344646636336335655565545355053640643034350665333366445650605465503305063353430433643563500553363343555335555654003556660353356400035554033350563036353664455633550463305646453360063600500554363656555364363303605665665363555004550336065640364504530634446546534335664656304033046345355433356633530363534333340353355005606565560335363053556360466006536350436033565536356350556455333534335335033334433063444300533453536600505304650556503455555063545354053033350363055430536056353555353530536505635353665004033543645033560035666555633630605355633604553354634435355355303633554433650654530506366663034653030033350455566604334663366344353353066603634330333530630003533634305350000004553046665404306553553504300635036560663565355645633335663336000455066605333033064453656303666363360666536306335354356354553650665350344505355550466563403555363636055545003033343533450363506633345665505455636056030400305546033553303335305365503566306334536533555006053634453443345035344330636030505463055036333055554006354630655550354530453346355030656535400534350533446035060346555353505656636355033360536054466046365350455445555456543030556355335550003463633636643444030634546305500603036365005636353554506650550503555500350604344634553445334405366366354450453555050655603364046533355655633533450564455444305653000606535505333654035433506430635'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'model.pth')"
      ],
      "metadata": {
        "id": "CCK7PR7aSotZ"
      },
      "execution_count": 120,
      "outputs": []
    }
  ]
}
